<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Markus Thill </title> <meta name="author" content="Markus Thill"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8D%95&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://markusthill.github.io/publications/"> <script src="/assets/js/theme.js?v=a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Markus</span> Thill </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/about">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/index.html">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus <span class="sr-only">(current)</span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item active" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?v=1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="krause2023" class="col-sm-8"> <div class="title">Process signal reconstruction and anomaly detection in laser machining processes</div> <div class="author"> Martin Krause, Markus Thill, and Fabian Mack </div> <div class="periodical"> <em>Patent US20230120761A1</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://patents.google.com/patent/US20230120761A1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">PhD thesis</abbr> <figure> <picture> <img src="/assets/img/publication_preview/phd.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="phd.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="thill2022machine" class="col-sm-8"> <div class="title">Machine Learning and Deep Learning Approaches for Multivariate Time Series Prediction and Anomaly Detection</div> <div class="author"> Markus Thill </div> <div class="periodical"> <em>PhD thesis</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://hdl.handle.net/1887/3279161" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/2022_phd_thill.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:WF5omc3nYNoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In many real-world applications today, it is critical to continuously record and monitor certain machine or system health indicators to discover malfunctions or other abnormal behavior at an early stage and prevent potential harm. The demand for such reliable monitoring systems is expected to increase in the coming years. Particularly in the industrial context, in the course of ongoing digitization, it is becoming increasingly important to analyze growing volumes of data in an automated manner using state-of-the-art algorithms. In many practical applications, one has to deal with temporal data in the form of data streams or time series. The problem of detecting unusual (or anomalous) behavior in time series is commonly referred to as time series anomaly detection. Anomalies are events observed in the data that do not conform to the normal or expected behavior when viewed in their temporal context.This thesis focuses on unsupervised machine learning algorithms for anomaly detection in time series. In an unsupervised learning setup, a model attempts to learn the normal behavior in a time series — which might already be contaminated with anomalies — without any external assistance. The model can then use its learned notion of normality to detect anomalous events. </p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ASoC</abbr> </div> <div id="thill2021" class="col-sm-8"> <div class="title">Temporal convolutional autoencoder for unsupervised anomaly detection in time series</div> <div class="author"> Markus Thill, Wolfgang Konen, Hao Wang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Thomas Bäck' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Applied Soft Computing (ASoC)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.asoc.2021.107751" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-251-4285F4?logo=googlescholar&amp;labelColor=beige" alt="251 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Learning temporal patterns in time series remains a challenging task up until today. Particularly for anomaly detection in time series, it is essential to learn the underlying structure of a system’s normal behavior. Periodic or quasiperiodic signals with complex temporal patterns make the problem even more challenging: Anomalies may be a hard-to-detect deviation from the normal recurring pattern. In this paper, we present TCN-AE, a temporal convolutional network autoencoder based on dilated convolutions. Contrary to many other anomaly detection algorithms, TCN-AE is trained in an unsupervised manner. The algorithm demonstrates its efficacy on a comprehensive real-world anomaly benchmark comprising electrocardiogram (ECG) recordings of patients with cardiac arrhythmia. TCN-AE significantly outperforms several other unsupervised state-of-the-art anomaly detection algorithms. Moreover, we investigate the contribution of the individual enhancements and show that each new ingredient improves the overall performance on the investigated benchmark.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">BIOMA</abbr> </div> <div id="Thill20a" class="col-sm-8"> <div class="title">Time Series Encodings with Temporal Convolutional Networks</div> <div class="author"> Markus Thill, Wolfgang Konen, and Thomas Bäck </div> <div class="periodical"> <em>In 9th International Conference on Bioinspired Optimisation Methods and Their Applications (BIOMA)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:YsMSGLbcyi4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-66-4285F4?logo=googlescholar&amp;labelColor=beige" alt="66 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The training of anomaly detection models usually requires labeled data. We present in this paper a novel approach for anomaly detection in time series which trains unsupervised using a convolutional approach coupled to an autoencoder framework. After training, only a small amount of labeled data is needed to adjust the anomaly threshold. We show that our new approach outperforms several other state-of-the-art anomaly detection algorithms on a Mackey-Glass (MG) anomaly benchmark. At the same time our autoencoder is capable of learning interesting representations in latent space. Our new MG anomaly benchmark allows to create an unlimited amount of anomaly benchmark data with steerable difficulty. In this benchmark, the anomalies are well-defined, yet difficult to spot for the human eye.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Thill20b" class="col-sm-8"> <div class="title">Predictive Maintenance &amp; Anomalie-Erkennung: Effiziente Instandhaltung mit Verfahren der KI</div> <div class="author"> Markus Thill and Wolfgang Konen </div> <div class="periodical"> 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ITAT</abbr> </div> <div id="Thill2019a" class="col-sm-8"> <div class="title">Anomaly Detection in Electrocardiogram Readings with Stacked LSTM Networks</div> <div class="author"> Markus Thill, Sina Däubner, Wolfgang Konen, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Thomas Bäck' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proc. 19th Conference Information Technologies - Applications and Theory (ITAT 2019)</em>, 2019 </div> <div class="periodical"> Best Paper Award </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-34-4285F4?logo=googlescholar&amp;labelColor=beige" alt="34 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Real-world anomaly detection for time series is still a challenging task. This is especially true for periodic or quasi-periodic time series since automated approaches have to learn long-term correlations before they are able to detect anomalies. Electrocardiography (ECG) time series, a prominent real-world example of quasi-periodic signals, are investigated in this work. Anomaly detection algorithms often have the additional goal to identify anomalies in an unsupervised manner. In this paper we present an unsupervised time series anomaly detection algorithm. It learns with recurrent Long Short-Term Memory (LSTM) networks to predict the normal time series behavior. The prediction error on several prediction horizons is used to build a statistical model of normal behavior. We propose new methods that are essential for a successful model-building process and for a high signal-to-noise-ratio. We apply our method to the well-known MIT-BIH ECG data set and present first results. We obtain a good recall of anomalies while having a very low false alarm rate (FPR) in a fully unsupervised procedure. We compare also with other anomaly detectors (NuPic, ADVec) from the state-of-the-art.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Buhl19" class="col-sm-8"> <div class="title">Deep Learning mit Keras und Tensorflow</div> <div class="author"> Henning Buhl, Wolfgang Konen, and Markus Thill </div> <div class="periodical"> 2019 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ThillKonenBaeck2018_1000097489" class="col-sm-8"> <div class="title">Online Adaptable Time Series Anomaly Detection with Discrete Wavelet Transforms and Multivariate Gaussian Distributions</div> <div class="author"> Markus Thill, Wolfgang Konen, and Thomas Bäck </div> <div class="periodical"> <em>Archives of Data Science, Series A (Online First)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:Y0pCki6q_DkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In this paper we present an unsupervised time series anomaly detection algorithm, which is based on the discrete wavelet transform (DWT) operating fully online. Given streaming data or time series, the algorithm iteratively computes the (causal and decimating) discrete wavelet transform. For individual frequency scales of the current DWT, the algorithm estimates the parameters of a multivariate Gaussian distribution. These parameters are adapted in an online fashion. Based on the multivariate Gaussian distributions, unusual patterns can then be detected across frequency scales, which in certain constellations indicate anomalous behavior. The algorithm is tested on a diverse set of 425 time series. A comparison to several other state-of-the-art online anomaly detectors shows that our algorithm can mostly produce results similar to the best algorithm on each dataset. It produces the highest average F1-score with one standard parameter setting. That is, it works more stable on high- and low-frequency-anomalies than all other algorithms. We believe that the wavelet transform is an important ingredient to achieve this.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Thill18" class="col-sm-8"> <div class="title">Reinforcement Learning for Strategic Board Games with N-Tuple Systems</div> <div class="author"> Markus Thill and Samineh Bagheri </div> <div class="periodical"> 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Thill2017c" class="col-sm-8"> <div class="title">Discrete Wavelet Transforms and Multivariate Gaussian Distributions for Anomaly Detection in Time Series</div> <div class="author"> Markus Thill, Wolfgang Konen, and Thomas Bäck </div> <div class="periodical"> <em>In Proceedings 27. Workshop Computational Intelligence</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>A new algorithm, based on the Discrete Wavelet Transform (DWT), for unsupervised anomaly detection in time series is introduced in this paper. The approach is based on using maximum likelihood estimation (MLE) on the DWT of time series. On a diverse set of 158 time series, the algorithm is compared with three other state-of-the-art anomaly detectors and it is shown to outperform the other approaches on the test set. Thanks to the linear time complexity of the DWT, our new algorithm is also computationally eﬃcient.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ITISE</abbr> </div> <div id="Thill17b-ITISE" class="col-sm-8"> <div class="title">Time Series Anomaly Detection with Discrete Wavelet Transforms and Maximum Likelihood Estimation</div> <div class="author"> Markus Thill, Wolfgang Konen, and Thomas Bäck </div> <div class="periodical"> <em>In International Work-Conference on Time Series (ITISE 2017)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:IjCSPb-OGe4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-40-4285F4?logo=googlescholar&amp;labelColor=beige" alt="40 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>A new algorithm, based on the Discrete Wavelet Transform (DWT), for unsupervised anomaly detection in time series is introduced in this paper. The approach is based on using maximum likelihood estimation (MLE) on the DWT of time series. On a diverse set of 158 time series, the algorithm is compared with three other state-of-the-art anomaly detectors and it is shown to outperform the other approaches on the test set. Thanks to the linear time complexity of the DWT, our new algorithm is also computationally efficient.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EAIS</abbr> </div> <div id="Thill17a-SORAD" class="col-sm-8"> <div class="title">Online Anomaly Detection on the Webscope S5 dataset: A Comparative Study</div> <div class="author"> Markus Thill, Wolfgang Konen, and Thomas Bäck </div> <div class="periodical"> <em>In IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS 2017)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-56-4285F4?logo=googlescholar&amp;labelColor=beige" alt="56 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>An unresolved challenge for all kind of temporal data is the reliable anomaly detection, especially when adaptability is required in the case of non-stationary time series or when the nature of future anomalies is unknown or only vaguely defined. Most of the current anomaly detection algorithms follow the general idea to classify an anomaly as a significant deviation from the prediction. In this paper we present a comparative study where several online anomaly detection algorithms are compared on the large Yahoo Webscope S5 anomaly benchmark. We show that a relatively Simple Online Regression Anomaly Detector (SORAD) is quite successful compared to other anomaly detectors. We discuss the importance of several adaptive and online elements of the algorithm and their influence on the overall anomaly detection accuracy.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE Trans. Games</abbr> </div> <div id="bagh16b" class="col-sm-8"> <div class="title">Online Adaptable Learning Rates for the Game Connect-4</div> <div class="author"> Samineh Bagheri, Markus Thill, Patrick Koch, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Wolfgang Konen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Transactions on Computational Intelligence and AI in Games</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Learning board games by self-play has a long tradition in computational intelligence for games. Based on Tesauro’s seminal success with TD-Gammon in 1994, many successful agents use temporal difference learning today. But in order to be successful with temporal difference learning on game tasks, often a careful selection of features and a large number of training games is necessary. Even for board games of moderate complexity like Connect-4, we found in previous work that a very rich initial feature set and several millions of game plays are required. In this work we investigate different approaches of online-adaptable learning rates like Incremental Delta Bar Delta (IDBD) or temporal coherence learning (TCL) whether they have the potential to speed up learning for such a complex task. We propose a new variant of TCL with geometric step size changes. We compare those algorithms with several other state-of-the-art learning rate adaptation algorithms and perform a case study on the sensitivity with respect to their meta parameters. We show that in this set of learning algorithms those with geometric step size changes outperform those other algorithms with constant step size changes. Algorithms with nonlinear output functions are slightly better than linear ones. Algorithms with geometric step size changes learn faster by a factor of 4 as compared to previously published results on the task Connect-4.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Masters thesis</abbr> </div> <div id="Thill2015a" class="col-sm-8"> <div class="title">Temporal Difference Learning Methods with Automatic Step-Size Adaption for Strategic Board Games: Connect-4 and Dots-and-Boxes</div> <div class="author"> Markus Thill </div> <div class="periodical"> <em>TH Köln – University of Applied Sciences</em>, 2015 </div> <div class="periodical"> Master thesis, Festo award 2015 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.gm.fh-koeln.de/%7Ekonen/research/PaperPDF/MT-Thill2015-final.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/MT-Thill2015-final.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Machine learning tasks for board games which rely solely on self-play methods remain rather challenging up till today. The perhaps most impressive breakthrough in this field was achieved by Tesauro’s TD-Gammon, which was able to learn the game backgammon at expert level with a self-play variant of the temporal difference learning (TDL) algorithm. Since then, many studies attempted to replicate some of TD-Gammon’s success by applying TDL to other board games, however, mostly with mixed results. We found in our earlier work on the board game Connect-4 that a rich feature set is required to successfully learn a near-perfect strategy. Nonetheless, several millions of self-play training games were necessary in order to generate strong Connect-4 agents. In this thesis we will mainly focus on two topics, namely online-adaptable learning rate methods and eligibility traces, and investigate whether these approaches have the potential to speed up learning. For the Connect-4 learning task we show that algorithms with geometric step-size changes have the best performance, in some cases reducing the required number of training games to learn the game by more than 40%. In a case study, we compare several state-of-the-art step-size adaptation algorithms with respect to their sensitivity towards certain meta parameters. In the further course of this thesis, we investigate the benefits of different eligibility trace variants. Additionally, we extend several learning rate algorithms to eligibility traces and examine their performance. We could observe that eligibility traces improve the speed of learning by a factor of two for our Connect-4 task. Overall, with several additional enhancements, we could reduce the number of training games to learn Connect-4 to slightly more than 100 000, which is an improvement by a factor of 13, compared to previously published results. In the last sections of this work, we apply the learning framework that we developed for Connect-4 – with several adjustments – to the strategic board game Dots-and-Boxes and discuss the main problems that we observed for our initial experiments. </p> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CIG</abbr> </div> <div id="Thil14" class="col-sm-8"> <div class="title">Temporal Difference Learning with Eligibility Traces for the Game Connect-4</div> <div class="author"> Markus Thill, Samineh Bagheri, Patrick Koch, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Wolfgang Konen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In CIG’2014, International Conference on Computational Intelligence in Games, Dortmund</em>, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-28-4285F4?logo=googlescholar&amp;labelColor=beige" alt="28 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Systems that learn to play board games are often trained by self-play on the basis of temporal difference (TD) learning. Successful examples include Tesauro’s well known TD-Gammon and Lucas’ Othello agent. For other board games of moderate complexity like Connect Four, we found in previous work that a successful system requires a very rich initial feature set with more than half a million of weights and several millions of training games. In this work we study the benefits of eligibility traces added to this system. To the best of our knowledge, eligibility traces have not been used before for such a large system. Different versions of eligibility traces (standard, resetting, and replacing traces) are compared. We show that eligibility traces speed up the learning by a factor of two and that they increase the asymptotic playing strength.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Bachelor thesis</abbr> </div> <div id="Thill12" class="col-sm-8"> <div class="title">Reinforcement Learning mit N-Tupel-Systemen für Vier Gewinnt</div> <div class="author"> Markus Thill </div> <div class="periodical"> <em>TH Köln – University of Applied Sciences</em>, 2012 </div> <div class="periodical"> Bachelor thesis, 1st prize in Opitz award 2013, Festo award 2012, Ferchau award 2012 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.gm.fh-koeln.de/ciopwebpub/Theses.d/Thill12.d/BA-Thill-2012.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/BA-Thill-2012.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Die Untersuchung maschineller Lernverfahren für Brettspiele stellt auch heute noch ein sehr interessantes Forschungsgebiet dar. Dies liegt vor allem daran, dass das Erlernen komplexer Spiele wie dem Schach- oder Go-Spiel nach wie vor als sehr anspruchsvoll gilt. Während Menschen in der Lage sind, gewisse Zusammenhänge bzw. Gesetzmäßigkeiten in Spielen zu erkennen und daraus die richtigen Rückschlüsse zu ziehen, ist dies für ein Computerprogramm deutlich schwieriger. Aus diesem Grund müssen die Entwickler häufig viel spieltheoretisches Wissen in das Programm einbringen, damit der Lernprozess überhaupt fähig ist, auf die besonderen spielspezifischen Merkmale zu achten. In dieser Arbeit wird die Anwendung von sogenannten N-Tupel-Systemen – in Kombination mit einer Reinforcement-Learning-Trainingsumgebung – auf das Spiel Vier Gewinnt untersucht. N-Tupel-Systeme dienen dazu, lineare Nutzenfunktionen von Agenten zu approximieren, sodass Stellungsbewertungen vorgenommen werden können. Um diese Funktionen zu erlernen, werden die N-Tupel-Systeme mithilfe des Temporal Difference Learnings (TDL), einem Algorithmus zur Lösung von RL- Problemen, trainiert. Das Training der Agenten erfolgte ausschließlich durch Self-Play, während des Trainings kam daher kein Lehrer oder spieltheoretisches Wissen irgendeiner Form zum Einsatz. Dennoch gelang es, Agenten mit hoher Spielstärke zu trainieren, die in vielen Fällen einen perfekten Spieler schlagen konnten. Insbesondere die N-Tupel-Systeme, die eine sehr große Zahl an Features generieren und die passenden selektieren, tragen zu den außerordentlich guten Ergebnissen bei.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">PPSN</abbr> </div> <div id="Thil12" class="col-sm-8"> <div class="title">Reinforcement learning with n-tuples on the game Connect-4</div> <div class="author"> Markus Thill, Patrick Koch, and Wolfgang Konen </div> <div class="periodical"> <em>In PPSN’2012: 12th International Conference on Parallel Problem Solving From Nature, Taormina</em>, 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Bu5eFxQAAAAJ&amp;citation_for_view=Bu5eFxQAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-33-4285F4?logo=googlescholar&amp;labelColor=beige" alt="33 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Learning complex game functions is still a difficult task. We apply temporal difference learning (TDL), a well-known variant of the reinforcement learning approach, in combination with n-tuple networks to the game Connect-4. Our agent is trained just by self-play. It is able, for the first time, to consistently beat the optimal-playing Minimax agent (in game situations where a win is possible). The n-tuple network induces a mighty feature space: It is not necessary to design certain features, but the agent learns to select the right ones. We believe that the n-tuple network is an important ingredient for the overall success and identify several aspects that are relevant for achieving high-quality results. The architecture is sufficiently general to be applied to similar reinforcement learning tasks as well.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Markus Thill. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a> and from <a href="https://www.freepik.com/" rel="external nofollow noopener" target="_blank">Freepik</a>. Last updated: January 17, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=b608866baffe761c7f8f7670a3310d0f"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=6f508d74becd347268a7f822bca7309d"></script> </body> </html>